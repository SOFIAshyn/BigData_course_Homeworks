{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType, DateType, TimestampType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir, outputDir = '/Users/sofiapetryshyn/Desktop/bigdata/hw3/input_data', \\\n",
    "                    '/Users/sofiapetryshyn/Desktop/bigdata/hw3/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SbOwzAl9ZfQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Capítulo 12 | MasterChef 2017</td>\n",
       "      <td>MasterChef 2017</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T06:06:22.000Z</td>\n",
       "      <td>MasterChef Junior 2017|\"TV Azteca\"|\"recetas\"|\"...</td>\n",
       "      <td>310130</td>\n",
       "      <td>4182</td>\n",
       "      <td>361</td>\n",
       "      <td>1836</td>\n",
       "      <td>https://i.ytimg.com/vi/SbOwzAl9ZfQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Disfruta la presencia del Chef Torreblanca en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>klOV6Xh-DnI</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...</td>\n",
       "      <td>Micky Contreras Martinez</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-13T05:11:58.000Z</td>\n",
       "      <td>La Voz Mexico 7</td>\n",
       "      <td>104972</td>\n",
       "      <td>271</td>\n",
       "      <td>174</td>\n",
       "      <td>369</td>\n",
       "      <td>https://i.ytimg.com/vi/klOV6Xh-DnI/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6L2ZF7Qzsbk</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>LOUIS CKAGÓ - EL PULSO DE LA REPÚBLICA</td>\n",
       "      <td>El Pulso De La República</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T17:00:02.000Z</td>\n",
       "      <td>Chumel Torres|\"El Pulso de la Republica\"|\"noti...</td>\n",
       "      <td>136064</td>\n",
       "      <td>10105</td>\n",
       "      <td>266</td>\n",
       "      <td>607</td>\n",
       "      <td>https://i.ytimg.com/vi/6L2ZF7Qzsbk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>La canción del principio se llama “Este espíri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hcY52MFWMDM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Sismo de 6.7 sacude Costa Rica 12 Noviembre 2017</td>\n",
       "      <td>Casanare</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-13T03:47:10.000Z</td>\n",
       "      <td>temblor|\"costa rica\"|\"sismo en costa rica\"</td>\n",
       "      <td>96153</td>\n",
       "      <td>378</td>\n",
       "      <td>171</td>\n",
       "      <td>208</td>\n",
       "      <td>https://i.ytimg.com/vi/hcY52MFWMDM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>El video es de un Walmart en el pais centroame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_OXDcGPVAa4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>DOG HACKS | MUSAS LESSLIE LOS POLINESIOS</td>\n",
       "      <td>Musas</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-13T19:17:48.000Z</td>\n",
       "      <td>MUSAS|\"lesslie\"|\"karen\"|\"hacks\"|\"perros\"|\"dogs...</td>\n",
       "      <td>499965</td>\n",
       "      <td>57781</td>\n",
       "      <td>681</td>\n",
       "      <td>7428</td>\n",
       "      <td>https://i.ytimg.com/vi/_OXDcGPVAa4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>MI HERMANO NARRA MI RUTINA DE MAQUILLAJE\\nhttp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  SbOwzAl9ZfQ      17.14.11   \n",
       "1  klOV6Xh-DnI      17.14.11   \n",
       "2  6L2ZF7Qzsbk      17.14.11   \n",
       "3  hcY52MFWMDM      17.14.11   \n",
       "4  _OXDcGPVAa4      17.14.11   \n",
       "\n",
       "                                               title  \\\n",
       "0                      Capítulo 12 | MasterChef 2017   \n",
       "1  ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...   \n",
       "2             LOUIS CKAGÓ - EL PULSO DE LA REPÚBLICA   \n",
       "3   Sismo de 6.7 sacude Costa Rica 12 Noviembre 2017   \n",
       "4           DOG HACKS | MUSAS LESSLIE LOS POLINESIOS   \n",
       "\n",
       "              channel_title  category_id              publish_time  \\\n",
       "0           MasterChef 2017           24  2017-11-13T06:06:22.000Z   \n",
       "1  Micky Contreras Martinez           22  2017-11-13T05:11:58.000Z   \n",
       "2  El Pulso De La República           25  2017-11-13T17:00:02.000Z   \n",
       "3                  Casanare           25  2017-11-13T03:47:10.000Z   \n",
       "4                     Musas           26  2017-11-13T19:17:48.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  MasterChef Junior 2017|\"TV Azteca\"|\"recetas\"|\"...  310130   4182       361   \n",
       "1                                    La Voz Mexico 7  104972    271       174   \n",
       "2  Chumel Torres|\"El Pulso de la Republica\"|\"noti...  136064  10105       266   \n",
       "3         temblor|\"costa rica\"|\"sismo en costa rica\"   96153    378       171   \n",
       "4  MUSAS|\"lesslie\"|\"karen\"|\"hacks\"|\"perros\"|\"dogs...  499965  57781       681   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0           1836  https://i.ytimg.com/vi/SbOwzAl9ZfQ/default.jpg   \n",
       "1            369  https://i.ytimg.com/vi/klOV6Xh-DnI/default.jpg   \n",
       "2            607  https://i.ytimg.com/vi/6L2ZF7Qzsbk/default.jpg   \n",
       "3            208  https://i.ytimg.com/vi/hcY52MFWMDM/default.jpg   \n",
       "4           7428  https://i.ytimg.com/vi/_OXDcGPVAa4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "2              False             False                   False   \n",
       "3              False             False                   False   \n",
       "4              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Disfruta la presencia del Chef Torreblanca en ...  \n",
       "1  ALEXA EX-INTEGRANTE DEL GRUPO TIMBIRICHE RENUN...  \n",
       "2  La canción del principio se llama “Este espíri...  \n",
       "3  El video es de un Walmart en el pais centroame...  \n",
       "4  MI HERMANO NARRA MI RUTINA DE MAQUILLAJE\\nhttp...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_file_df = pd.read_csv(os.path.join(inputDir, \\\n",
    "                                       list(filter(lambda file: file.endswith('csv'), os.listdir(inputDir)))[0]))\n",
    "one_file_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Find Top 10 videos that were amongst the trending videos for the highest number of days (it doesn't need to be a consecutive period of time). You should also include information about different metrics for each day the video was trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       video_id  trending_date\n",
      "1   siphkFpHQhs              4\n",
      "2   ejhNHlFuhz0              4\n",
      "3   xTlNMmZKwpA              4\n",
      "4   FRMw8hiphrc              4\n",
      "5   FVRPzwb1Vi4              4\n",
      "6   ezcKDkH1OZc              4\n",
      "7   tLOl3s0uIM4              4\n",
      "8   FlsCjmMhFmw              4\n",
      "9   ZRx76gi8aUA              4\n",
      "10  mIL-eTj5udg              4\n"
     ]
    }
   ],
   "source": [
    "res_dict = {}\n",
    "\n",
    "df_unique = one_file_df.groupby('video_id')['trending_date'].nunique()\\\n",
    "    .reset_index().sort_values(by=['trending_date'], ascending=False).reset_index(drop=True)\n",
    "df_unique = df_unique.loc[df_unique.video_id != '#NAME?'][:10]\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: MX\n",
      "Country: IN\n",
      "Country: DE\n",
      "Country: JP\n",
      "Country: KR\n",
      "Country: CA\n",
      "Country: RU\n",
      "Country: FR\n",
      "Country: US\n",
      "Country: GB\n"
     ]
    }
   ],
   "source": [
    "# For one region\n",
    "task = 1\n",
    "for file in list(filter(lambda file: file.endswith('csv'), os.listdir(inputDir))):\n",
    "    country = file[:2]\n",
    "    print(f'Country: {country}')\n",
    "    file = os.path.join(inputDir, file)\n",
    "    one_file_df = pd.read_csv(file)\n",
    "    \n",
    "    df_unique = one_file_df.groupby('video_id')['trending_date'].nunique()\\\n",
    "                .reset_index().sort_values(by=['trending_date'], ascending=False).reset_index(drop=True)\n",
    "    df_unique = df_unique.loc[df_unique.video_id != '#NAME?'][:10]\n",
    "    \n",
    "    video_arr = []\n",
    "    # For one trending video\n",
    "    for video_id in df_unique.video_id:\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['id'] = str(video_id)\n",
    "        tmp_series = one_file_df.loc[one_file_df.video_id == video_id].head(1)\n",
    "        tmp_dict['title'] = str(tmp_series.title.values[0])\n",
    "        tmp_dict['description'] = str(tmp_series.description.values[0])\n",
    "        tmp_dict['latest_views'] = int(tmp_series.views.values[0])\n",
    "        tmp_dict['latest_likes'] = int(tmp_series.likes.values[0])\n",
    "        tmp_dict['latest_dislikes'] = int(tmp_series.dislikes.values[0])\n",
    "        tmp_dict['trending_days'] = [\n",
    "            {\n",
    "                'date': str(series[1].trending_date),\n",
    "                'views': int(series[1].views),\n",
    "                'likes': int(series[1].likes),\n",
    "                'dislikes': int(series[1].dislikes),\n",
    "            }\n",
    "            for series in one_file_df.loc[one_file_df.video_id == video_id].iterrows()\n",
    "        ]\n",
    "\n",
    "        video_arr.append(tmp_dict)\n",
    "\n",
    "\n",
    "    res_dict = {\n",
    "        'videos': video_arr\n",
    "    }\n",
    "    cur_dir = f'./output/copycat_inc/{task}/{country}'\n",
    "    os.makedirs(cur_dir)\n",
    "    out_file = open(os.path.join(cur_dir, 'result.json'), \"w+\")\n",
    "    json.dump(res_dict, out_file, indent=4)\n",
    "    out_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Find what was the most popular category for each week (7 days slices). Popularity is decided based on the total number of views for videos of this category. Note, to calculate it you can’t just sum up the number of views. If a particular video appeared only once during the given period, it shouldn’t be counted. Only if it appeared more than once you should count the number of new views. For example, if video A appeared on day 1 with 100 views, then on day 4 with 250 views and again on day 6 with 400 views, you should count it as 400 - 100 = 300. For our purpose, it will mean that this particular video was watched 300 times in the given time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>christmas|\"john lewis christmas\"|\"john lewis\"|...</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Click here to continue the story and make your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3s1rvMFUweQ</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Taylor Swift: …Ready for It? (Live) - SNL</td>\n",
       "      <td>Saturday Night Live</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T06:24:44.000Z</td>\n",
       "      <td>SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...</td>\n",
       "      <td>1053632</td>\n",
       "      <td>25561</td>\n",
       "      <td>2294</td>\n",
       "      <td>2757</td>\n",
       "      <td>https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Musical guest Taylor Swift performs …Ready for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date                                          title  \\\n",
       "0  Jw1Y-zhQURU      17.14.11  John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "1  3s1rvMFUweQ      17.14.11      Taylor Swift: …Ready for It? (Live) - SNL   \n",
       "\n",
       "         channel_title  category_id              publish_time  \\\n",
       "0           John Lewis           26  2017-11-10T07:38:29.000Z   \n",
       "1  Saturday Night Live           24  2017-11-12T06:24:44.000Z   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  christmas|\"john lewis christmas\"|\"john lewis\"|...  7224515  55681   \n",
       "1  SNL|\"Saturday Night Live\"|\"SNL Season 43\"|\"Epi...  1053632  25561   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     10247           9479  https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg   \n",
       "1      2294           2757  https://i.ytimg.com/vi/3s1rvMFUweQ/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Click here to continue the story and make your...  \n",
       "1  Musical guest Taylor Swift performs …Ready for...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_file_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: MX\n",
      "Country: IN\n",
      "Country: DE\n",
      "Country: JP\n",
      "Country: KR\n",
      "Country: CA\n",
      "Country: RU\n",
      "Country: FR\n",
      "Country: US\n",
      "Country: GB\n"
     ]
    }
   ],
   "source": [
    "task = 2\n",
    "for file in list(filter(lambda file: file.endswith('csv'), os.listdir(inputDir))):\n",
    "    country = file[:2]\n",
    "    print(f'Country: {country}')\n",
    "    file = os.path.join(inputDir, file)\n",
    "    one_file_df = pd.read_csv(file)\n",
    "    one_file_df.trending_date = list(map(lambda date_: datetime.strptime('20' + date_, '%Y.%d.%m'), \\\n",
    "                                         one_file_df.trending_date))\n",
    "    one_file_df = one_file_df.loc[one_file_df.video_id != '#NAME?']\n",
    "    start_d = one_file_df.trending_date.min()\n",
    "    res_dict = {\n",
    "        'weeks': []\n",
    "    }\n",
    "    # For each week\n",
    "    while start_d <= one_file_df.trending_date.max():\n",
    "        end_period = start_d + timedelta(days=7)\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['start_date'] = str(start_d)\n",
    "        tmp_dict['end_date'] = str(end_period)\n",
    "        week_df = one_file_df.loc[(start_d <= one_file_df.trending_date) & (one_file_df.trending_date < end_period)]\n",
    "        v = week_df.video_id.value_counts()\n",
    "        week_df = week_df[week_df.video_id.isin(v.index[v.gt(2)])]\n",
    "        \n",
    "        category_dict = {}\n",
    "        category_videos_dict = {}\n",
    "        # For all the video occurances\n",
    "        for video_id in set(week_df.video_id):\n",
    "            week_video_df = week_df.loc[(week_df.video_id == video_id)]\n",
    "            num_of_views_during_the_week = week_video_df.tail(1).\\\n",
    "                                            views.values[0] - week_video_df.head(1).views.values[0]\n",
    "\n",
    "            cur_category = week_video_df.head(1).category_id.values[0]\n",
    "            \n",
    "            if category_videos_dict.get(cur_category, None) is None:\n",
    "                category_videos_dict[cur_category] = []\n",
    "            category_videos_dict[cur_category].append(str(week_video_df.head(1).video_id.values[0]))\n",
    "            \n",
    "            if category_dict.get(cur_category, None) is None:\n",
    "                category_dict[cur_category] = 0\n",
    "            category_dict[cur_category] += num_of_views_during_the_week\n",
    "\n",
    "        max_category_id = max(category_dict.items(), key=operator.itemgetter(1))[0]\n",
    "        tmp_dict['category_id'] = int(max_category_id)\n",
    "        tmp_dict['number_of_videos'] = int(len(category_videos_dict[max_category_id]))\n",
    "        tmp_dict['total_views'] = int(category_dict[max_category_id])\n",
    "        tmp_dict['video_ids'] = category_videos_dict[cur_category]\n",
    "        # each week dictionsry\n",
    "        res_dict['weeks'].append(tmp_dict)\n",
    "        start_d = end_period\n",
    "    \n",
    "    cur_dir = f'./output/copycat_inc/{task}/{country}'\n",
    "    os.makedirs(cur_dir)\n",
    "    out_file = open(os.path.join(cur_dir, 'result.json'), \"w+\")\n",
    "    json.dump(res_dict, out_file, indent=4)\n",
    "    out_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "What were the 10 most used tags amongst trending videos for each 30days time period? Note, if during the specified period the same video appears multiple times, you should count tags related to that video only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jw1Y-zhQURU</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>John Lewis Christmas Ad 2017 - #MozTheMonster</td>\n",
       "      <td>John Lewis</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-11-10T07:38:29.000Z</td>\n",
       "      <td>christmas|\"john lewis christmas\"|\"john lewis\"|...</td>\n",
       "      <td>7224515</td>\n",
       "      <td>55681</td>\n",
       "      <td>10247</td>\n",
       "      <td>9479</td>\n",
       "      <td>https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Click here to continue the story and make your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date                                          title  \\\n",
       "0  Jw1Y-zhQURU    2017-11-14  John Lewis Christmas Ad 2017 - #MozTheMonster   \n",
       "\n",
       "  channel_title  category_id              publish_time  \\\n",
       "0    John Lewis           26  2017-11-10T07:38:29.000Z   \n",
       "\n",
       "                                                tags    views  likes  \\\n",
       "0  christmas|\"john lewis christmas\"|\"john lewis\"|...  7224515  55681   \n",
       "\n",
       "   dislikes  comment_count                                  thumbnail_link  \\\n",
       "0     10247           9479  https://i.ytimg.com/vi/Jw1Y-zhQURU/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Click here to continue the story and make your...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: MX\n",
      "Country: IN\n",
      "Country: DE\n",
      "Country: JP\n",
      "Country: KR\n",
      "Country: CA\n",
      "Country: RU\n",
      "Country: FR\n",
      "Country: US\n",
      "Country: GB\n"
     ]
    }
   ],
   "source": [
    "task = 3\n",
    "for file in list(filter(lambda file: file.endswith('csv'), os.listdir(inputDir))):\n",
    "    country = file[:2]\n",
    "    print(f'Country: {country}')\n",
    "    file = os.path.join(inputDir, file)\n",
    "    one_file_df = pd.read_csv(file)\n",
    "    one_file_df.trending_date = list(map(lambda date_: datetime.strptime('20' + date_, '%Y.%d.%m'), \\\n",
    "                                         one_file_df.trending_date))\n",
    "    one_file_df = one_file_df.loc[one_file_df.video_id != '#NAME?']\n",
    "    start_d = one_file_df.trending_date.min()\n",
    "    res_dict = {\n",
    "        'months': []\n",
    "    }\n",
    "    \n",
    "    # For each month\n",
    "    while start_d <= one_file_df.trending_date.max():\n",
    "        end_period = start_d + timedelta(days=30)\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['start_date'] = str(start_d)\n",
    "        tmp_dict['end_date'] = str(end_period)\n",
    "        month_df = one_file_df.loc[(start_d <= one_file_df.trending_date) & (one_file_df.trending_date < end_period)]\n",
    "        month_df = month_df.drop_duplicates(subset=['video_id'])\n",
    "        \n",
    "        month_tags = []\n",
    "        for video_row in month_df.iterrows():\n",
    "            month_tags += list(filter(lambda tag: tag != '[none]', video_row[1].tags.replace(\"'\", \"\").replace(\"\\\"\", \"\").split('|')))\n",
    "        month_tags_counter = Counter(month_tags)\n",
    "        top_10_tags_counts = month_tags_counter.most_common(10)\n",
    "        top_10_tags = [el[0] for el in top_10_tags_counts]\n",
    "        tmp_dict['tags'] = []\n",
    "        \n",
    "        for cur_tag in top_10_tags:\n",
    "            mask = month_df.tags.apply(lambda x: any(tag for tag in [cur_tag] if tag in x.replace(\"'\", \"\").replace(\"\\\"\", \"\").split('|')))\n",
    "            month_videos_with_tags = [video for video in month_df[mask].video_id.values]\n",
    "            \n",
    "            tmp_dict['tags'].append(\n",
    "                {\n",
    "                    'tag': cur_tag,\n",
    "                    'number_of_videos': len(month_videos_with_tags),\n",
    "                    'video_ids': month_videos_with_tags\n",
    "                }\n",
    "            )\n",
    "#         print(tmp_dict)\n",
    "        res_dict['months'].append(tmp_dict)        \n",
    "        start_d = end_period\n",
    "    \n",
    "    cur_dir = f'./output/copycat_inc/{task}/{country}'\n",
    "    os.makedirs(cur_dir)\n",
    "    out_file = open(os.path.join(cur_dir, 'result.json'), \"w+\")\n",
    "    json.dump(res_dict, out_file, indent=4)\n",
    "    out_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Show the top 20 channels by the number of views for the whole period. Note, if there are multiple appearances of the same video for some channel, you should take into account only the last appearance (with the highest number of views)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(one_file_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster('local')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaDf = StructType([\n",
    "    StructField(\"video_id\", StringType()),\n",
    "    StructField(\"trending_date\", DateType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"channel_title\", StringType()),\n",
    "    StructField(\"category_id\", IntegerType()),\n",
    "    StructField(\"publish_time\", TimestampType()),\n",
    "    StructField(\"tags\", StringType()),\n",
    "    StructField(\"views\", IntegerType()),\n",
    "    StructField(\"likes\", IntegerType()),\n",
    "    StructField(\"dislikes\", IntegerType()),\n",
    "    StructField(\"comment_count\", IntegerType()),\n",
    "    StructField(\"thumbnail_link\", StringType()),\n",
    "    StructField(\"comments_disabled\", BooleanType()),\n",
    "    StructField(\"ratings_disabled\", BooleanType()),\n",
    "    StructField(\"video_error_or_removed\", BooleanType()),\n",
    "    StructField(\"description\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|   video_id|count|\n",
      "+-----------+-----+\n",
      "|1q41CjSKa7s|    1|\n",
      "|VvsVDp0aYHY|    1|\n",
      "|3W9uwoM3WAc|    1|\n",
      "|vDsDg7iuT-A|    1|\n",
      "|MsRWkjuhblg|    1|\n",
      "|hM23vXlT_VY|    1|\n",
      "|5tHyEZvqbpE|    1|\n",
      "|P7MJnELbCIk|    1|\n",
      "|8NXpfS2wSic|    1|\n",
      "|JFMVjX5Jexo|    1|\n",
      "|R7rNcvcM5Ag|    2|\n",
      "|dSZTHvARYPg|    1|\n",
      "|R420j7DG_Ik|    2|\n",
      "|mGwuSNAVvTc|    1|\n",
      "|pKMTAU14-7s|    1|\n",
      "|42KMIRozQcM|    2|\n",
      "|173_sjiKXQk|    1|\n",
      "|G_Ar-vHo10Q|    1|\n",
      "|B8_7vu1Akpk|    1|\n",
      "|VX1geS-D3oU|    2|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for file in list(filter(lambda file: file.endswith('csv'), os.listdir(inputDir))):\n",
    "    file = os.path.join(inputDir, file)\n",
    "    df = sqlContext.read \\\n",
    "        .format('com.databricks.spark.csv') \\\n",
    "        .options(header='true') \\\n",
    "        .load(file, schema = schemaDf)\n",
    "    \n",
    "#     print(df.select('video_id', 'trending_date').collect())\n",
    "#     break\n",
    "    \n",
    "    print(df.select('video_id', 'trending_date').groupBy('video_id').count().show())\n",
    "    break\n",
    "    \n",
    "#     o_file = os.path.join(outputDir, 'newcars.csv')\n",
    "#     df.select('video_id', 'trending_date').write \\\n",
    "#     .format('com.databricks.spark.csv') \\\n",
    "#     .save(o_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.31.249:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
